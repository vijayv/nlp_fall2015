{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Word2Vec Demo##\n",
    "From https://github.com/nltk/nltk/blob/develop/nltk/test/gensim.doctest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to get gensim, to to https://radimrehurek.com/gensim/\n",
    "# OR run this on your command line: easy_install -U gensim \n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.data import find\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To get the model file needed, do the following one time only:\n",
    "#one time only: Run download; view the UI that pops up; switch to the models tab, and download the word2vec_sample model\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "model = gensim.models.Word2Vec.load_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pruned the model to only include the most common words (~44k words).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43981"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each word is represented in the space of 300 dimensions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model['university'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the top n words that are similar to a target word is simple. The result is the list of n words with the score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('universities', 0.7003918290138245),\n",
       " ('faculty', 0.6780907511711121),\n",
       " ('undergraduate', 0.6587095260620117),\n",
       " ('campus', 0.6434987783432007),\n",
       " ('college', 0.6385269165039062),\n",
       " ('academic', 0.6317198276519775),\n",
       " ('professors', 0.6298646926879883),\n",
       " ('undergraduates', 0.6149813532829285),\n",
       " ('University', 0.6139305233955383),\n",
       " ('student', 0.6005401611328125)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['university'], topn = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding a word that is not in a list is also supported in the API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match('breakfast cereal dinner lunch'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mikolov et al. (2013) figured out the following famous exampe:  word embedding captures much of syntactic and semantic regularities. For example,\n",
    "the vector 'King - Man + Woman' is close to 'Queen' and 'Germany - Berlin + Paris' is close to 'France'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192911148071)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman','king'], negative=['man'], topn = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.42707839608192444),\n",
       " ('monarch', 0.3571931719779968),\n",
       " ('thrones', 0.32843494415283203),\n",
       " ('queens', 0.3282967805862427),\n",
       " ('kingdom', 0.3216303586959839),\n",
       " ('courtiers', 0.3147016763687134),\n",
       " ('throne', 0.3120730519294739),\n",
       " ('royal', 0.29855966567993164),\n",
       " ('kings', 0.29191964864730835),\n",
       " ('Camilla', 0.27846354246139526)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman','king'], negative=['man', 'boy'], topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('France', 0.7884091138839722)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['Paris','Germany'], negative=['Berlin'], topn = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chancellor', 0.6200418472290039),\n",
       " ('dean', 0.6120452880859375),\n",
       " ('President', 0.591903805732727),\n",
       " ('faculty', 0.5726973414421082),\n",
       " ('rector', 0.5606599450111389),\n",
       " ('presidents', 0.5546602606773376),\n",
       " ('Provost', 0.5418164730072021),\n",
       " ('regents', 0.5399488210678101),\n",
       " ('professors', 0.5367733240127563),\n",
       " ('universities', 0.5157524347305298),\n",
       " ('campus', 0.5094808340072632),\n",
       " ('student', 0.5033937692642212),\n",
       " ('academic', 0.5031865835189819),\n",
       " ('institute', 0.5005171895027161),\n",
       " ('undergraduate', 0.48198601603507996),\n",
       " ('Professors', 0.47340402007102966),\n",
       " ('professor', 0.47276201844215393),\n",
       " ('Faculty', 0.47209471464157104),\n",
       " ('chairman', 0.4699815511703491),\n",
       " ('professorship', 0.467648446559906),\n",
       " ('presidency', 0.46344324946403503),\n",
       " ('University', 0.45916348695755005),\n",
       " ('campuses', 0.45756882429122925),\n",
       " ('college', 0.45753854513168335),\n",
       " ('trustees', 0.45137834548950195),\n",
       " ('Chancellor', 0.4487611949443817),\n",
       " ('undergraduates', 0.4440937042236328),\n",
       " ('institution', 0.4374503493309021),\n",
       " ('endowment', 0.4351673722267151),\n",
       " ('Trustees', 0.433601975440979)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['president', 'university'], topn=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can train your own models.  Here is an example using NLTK corpora.  This will be an exercise in seeing how different corpora yield different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_model = gensim.models.Word2Vec(brown.sents())\n",
    "\n",
    "# It might take some time to train the model. So, after it is trained, it can be saved as follows:\n",
    "\n",
    "brown_model.save('brown.embedding')\n",
    "new_model = gensim.models.Word2Vec.load('brown.embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hengesbach', 0.9018814563751221),\n",
       " ('Corp.', 0.89886873960495),\n",
       " ('superintendent', 0.8922324180603027),\n",
       " ('Cardinals', 0.8915742635726929),\n",
       " ('Larson', 0.8907597661018372),\n",
       " ('Monte', 0.8878529071807861),\n",
       " ('Railroad', 0.884084939956665),\n",
       " ('dean', 0.8820680975914001),\n",
       " ('Football', 0.8818255662918091),\n",
       " ('upheld', 0.8803490400314331)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_model.most_similar('president')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
