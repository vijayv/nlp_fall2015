{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The NLTK book assumes we import these each time\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several ways to remove punctuation.  The first is to make a list of punctuation manually, and remove those words that do not match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "punctuation = [':', ',', '.', '!', '\\'', '[', ']']\n",
    "nopunct = [w for w in text6 if w not in punctuation]\n",
    "' '.join(nopunct[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next is to use isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = [x for x in text6 if x.isalpha()]\n",
    "' '.join(alpha[200:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "For text with numbers, you can alternatively use isalnum (alphanumeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alnum = [x for x in text6 if x.isalnum()]\n",
    "' '.join(alnum[1000:1100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use the string.punctuation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "nopunct = [w for w in text6 if w not in string.punctuation]\n",
    "' '.join(nopunct[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to look words up in a wordlist, but then you miss the names of the characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "normalized = [w for w in text6 if w.lower() not in stopwords.words('english') and w not in string.punctuation]\n",
    "' '.join(normalized[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's process more gnarly text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "raw = \"\"\"'When I'M a Duchess,' she said to herself, (not in a very hopeful tone\n",
    "... though), 'I won't have any pepper in my kitchen AT ALL. Soup does very\n",
    "... well without--Maybe it's always pepper that makes people hot-tempered,'...\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, just split on simple white space (blanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(re.split(r' ',raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the punctuation is not separated out.  To fix that; explicitly look for the tabs and newlines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(re.split(r'[ \\t\\n]+', raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use \\w for word characters, equivalent to [a-zA-Z0-9_]. The capital \\W+ splits on everything **other** than the word class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(re.findall(r'\\w+', raw))\n",
    "print(re.split(r'\\W+', raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now the contraction *I'm* is split up, which is a problem!  And we are losing the punctuation we do want, like those hyphens and apostrophes that do have meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get more complicated:\n",
    "* \\w+ to match words \n",
    "* \\w+(?:[-']\\w+)*|' to match word-internal hyphens and apostrophes\n",
    "* \\S+ to match non-whitespace characters (the complement of spaces)\n",
    "* followed by \\w* to optionally match more words\n",
    "* precede these with [-.(]+ to match double hyphen, ellipses, and open parentheses, which are to be tokenized separately.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(re.findall(r\"\\w+(?:[-']\\w+)*|'|[-.(]+|\\S\\w*\", raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does that ?: mean?  Here is a comparison.  This first findall both finds the pattern and selects it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.findall(r'^.*(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second one, using the ?:, suppresses the selecting out of the pattern, and just does the matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.findall(r'^.*(?:ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to the complex tokenization pattern, is there an easier way?\n",
    "nltk.regex_tokenize() might be worth a shot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern = r'''(?x)    # set flag to allow verbose regexps\n",
    "...     ([A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "...   | \\w+([-']\\w+)*        # words with optional internal hyphens\n",
    "...   | \\$?\\d+(\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
    "...   | \\.\\.\\.            # ellipsis\n",
    "...   | [.,;\"'?():-_`]+  # these are separate tokens\n",
    "... '''\n",
    "print(nltk.regexp_tokenize(raw,pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This still makes errors -- When is separated into two terms because of the initial apostrophe, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
