{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's compare stemmers!\n",
    "First load in the libraries and set up the stemmers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "from nltk.corpus import gutenberg\n",
    "import re\n",
    "import string\n",
    "pstemmer = nltk.PorterStemmer()\n",
    "lstemmer = nltk.LancasterStemmer()\n",
    "wnlemmatizer = nltk.WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also need a bit of tokenization and normalization here.  \n",
    "**Add some code here to remove punctuation and stopwords.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):    \n",
    "    pattern = r'''(?x)\n",
    "    ([A-Z]\\.)+\n",
    "    |\\w+([-']\\w+)*\n",
    "    |\\$?\\d+(\\.\\d+)?%?\n",
    "    |\\.\\.\\.\n",
    "    |[.,?;]+\n",
    "    '''\n",
    "    tokens = nltk.regexp_tokenize(text,pattern)\n",
    "    tokens = filter(lambda x: not(x.lower() in english_stopwords) and not(x in string.punctuation), tokens)\n",
    "    return list(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tokenize Shakespeare's Julius Ceaser; make sure it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11130\n",
      "['Tragedie', 'Julius', 'Caesar', 'William', 'Shakespeare', '1599', 'Actus', 'Primus', 'Scoena', 'Prima']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenize_text(gutenberg.raw('shakespeare-caesar.txt'))\n",
    "print (len(tokens))\n",
    "print(tokens[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is one example of running the stemmer; ** you can fill in the other two.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pstemmed_tokens = [pstemmer.stem(word.lower()) for word in tokens]\n",
    "lstemmed_tokens = [lstemmer.stem(word.lower()) for word in tokens]\n",
    "wnlemma_tokens = [wnlemmatizer.lemmatize(word.lower()) for word in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we want make 3 FreqDists to count up how common each word is now that we've done the stemming.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fd1 = nltk.FreqDist(pstemmed_tokens)\n",
    "fd2 = nltk.FreqDist(lstemmed_tokens)\n",
    "fd3 = nltk.FreqDist(wnlemma_tokens)\n",
    "\n",
    "fd1_most_common = fd1.most_common(20)\n",
    "fd2_most_common = fd2.most_common(20)\n",
    "fd3_most_common = fd3.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to compare the three outputs.  **What is a good function that quickly lets you do side-by-side comparisons of vertical lists?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pstemmed         lsstemmed        wnstemmed       \n",
      "('caesar', 228)  ('caes', 228)    ('caesar', 228) \n",
      "('brutu', 161)   ('brut', 200)    ('brutus', 161) \n",
      "('bru', 153)     ('bru', 153)     ('bru', 153)    \n",
      "('haue', 147)    ('hau', 149)     ('haue', 147)   \n",
      "('shall', 125)   ('shal', 125)    ('shall', 125)  \n",
      "('thou', 115)    ('cass', 117)    ('thou', 115)   \n",
      "('cassi', 107)   ('thou', 115)    ('cassi', 107)  \n",
      "('come', 89)     ('com', 93)      ('come', 89)    \n",
      "('cassiu', 85)   ('cassi', 85)    ('cassius', 85) \n",
      "('antoni', 76)   ('antony', 76)   ('antony', 76)  \n",
      "('know', 71)     ('let', 73)      ('good', 70)    \n",
      "('good', 70)     ('rom', 73)      ('o', 69)       \n",
      "('o', 69)        ('know', 71)     ('know', 68)    \n",
      "('men', 66)      ('cask', 70)     ('men', 66)     \n",
      "('enter', 65)    ('good', 70)     ('let', 64)     \n",
      "('let', 64)      ('o', 69)        ('enter', 64)   \n",
      "('vs', 62)       ('men', 66)      ('v', 62)       \n",
      "('man', 58)      ('ent', 66)      ('man', 58)     \n",
      "('heer', 56)     ('vs', 62)       ('thy', 56)     \n",
      "('thi', 56)      ('man', 61)      ('heere', 56)   \n"
     ]
    }
   ],
   "source": [
    "print('%-16s' % 'pstemmed', '%-16s' % 'lsstemmed', '%-16s' % 'wnstemmed')\n",
    "for i in range(0, len(fd1_most_common)):\n",
    "    print('%-16s' % str(fd1_most_common[i]), '%-16s' % str(fd2_most_common[i]), '%-16s' % str(fd3_most_common[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What worked well for each stemmer, and what did not?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to analyze your data.  How do the outputs differ?  How are they similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
