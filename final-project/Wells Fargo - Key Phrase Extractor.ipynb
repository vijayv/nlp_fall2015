{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>MediaType</th>\n",
       "      <th>FullText</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AutoID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/26/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>3 ways the internet of things will change Bank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/5/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>BankB BankB Name downgrades apple stock to neu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/12/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>BankB returns to profit on INTERNET/! board2? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/5/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>BankB tells advisers to exit paulson hedge fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8/12/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>BankC may plead guilty over foreign exchange p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date  Year  Month MediaType  \\\n",
       "AutoID                                     \n",
       "1       8/26/2015  2015      8   twitter   \n",
       "2        8/5/2015  2015      8   twitter   \n",
       "3       8/12/2015  2015      8   twitter   \n",
       "4        8/5/2015  2015      8   twitter   \n",
       "5       8/12/2015  2015      8   twitter   \n",
       "\n",
       "                                                 FullText  \n",
       "AutoID                                                     \n",
       "1       3 ways the internet of things will change Bank...  \n",
       "2       BankB BankB Name downgrades apple stock to neu...  \n",
       "3       BankB returns to profit on INTERNET/! board2? ...  \n",
       "4       BankB tells advisers to exit paulson hedge fun...  \n",
       "5       BankC may plead guilty over foreign exchange p...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"dataset.txt\", delimiter=\"|\", encoding=\"ISO-8859-1\", index_col=\"AutoID\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn, brown\n",
    "\n",
    "def filter_terms(in_str, sub_list=None):\n",
    "    if sub_list is None:\n",
    "        return in_str\n",
    "\n",
    "    for pattern in sub_list:\n",
    "        in_str = re.sub(\"\\\\b\" + pattern + \"\\\\b\", '', in_str)\n",
    "\n",
    "    return in_str\n",
    "\n",
    "def get_sents(collection):\n",
    "    sent_tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sents = sent_tokenizer.tokenize(collection) \n",
    "    return [nltk.word_tokenize(word) for word in raw_sents]\n",
    "\n",
    "def pos_tagger(train_sents):\n",
    "    return nltk.pos_tag(train_sents)\n",
    "\n",
    "def traverse(t):\n",
    "    try:\n",
    "        t.label()\n",
    "    except AttributeError:\n",
    "        return\n",
    "    else:\n",
    "        if t.label() == 'NP':  \n",
    "            print(t)\n",
    "        # or do something else\n",
    "        else:\n",
    "            for child in t:\n",
    "                traverse(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Common Bi-Grams\n",
    "# ('financial', 'advisers'), \n",
    "# ('wealth', 'managers’),\n",
    "# ('bank', 'account’),\n",
    "# ('debit', 'card’), \n",
    "# ('credit', 'card’),\n",
    "# ('checking', 'account’),\n",
    "# ('close', 'account’),\n",
    "# ('worst', 'bank’),\n",
    "# ('data', 'breach’),\n",
    "# ('bank', 'robbery’),\n",
    "# ('new', 'bank’),\n",
    "# ('cash', 'check’),\n",
    "# ('direct', 'deposit’),\n",
    "# ('open', 'account’),\n",
    "# ('bank', 'card'),\n",
    "# ('savings', 'account'),\n",
    "# ('online', 'banking’),\n",
    "# ('account', 'number'),\n",
    "# ('asset', 'management’)\n",
    "\n",
    "topics = [\"financial advisers\", \"customer service\", \"credit card\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Facebook Comments that mention financial advisers: 2140\n",
      "Twitter Comments that mention financial advisers: 3\n",
      "\n",
      "Key Phrases from Facebook\n",
      "(NP is/VBZ still/RB plenty/JJ)\n",
      "(NP is/VBZ still/RB plenty/JJ)\n",
      "(NP tesco/NN is/VBZ still/RB unclear/JJ BankD/NNP)\n",
      "(NP weakness/NN means/VBZ key/JJ issues/NNS)\n",
      "(NP weakness/NN means/VBZ key/JJ issues/NNS)\n",
      "(NP\n",
      "  buyers/NNS\n",
      "  INTERNET/NNP\n",
      "  alpari/NN\n",
      "  uk/NN\n",
      "  has/VBZ\n",
      "  potential/JJ\n",
      "  buyers/NNS)\n",
      "(NP forex/NN INTERNET/NN barclays/NNS sets/VBZ aside/JJ â/NNP)\n",
      "(NP Name/NNP Name/NNP boosts/VBZ easy-access/JJ savings/NNS)\n",
      "(NP\n",
      "  airways/NNS\n",
      "  Name/NNP\n",
      "  owner/NN\n",
      "  Name/NNP\n",
      "  makes/VBZ\n",
      "  third/JJ\n",
      "  offer/NN)\n",
      "(NP Name/NNP owner/NN Name/NNP makes/VBZ third/JJ offer/NN)\n",
      "(NP bytemark/NN makes/VBZ first/JJ acquisition/NN)\n",
      "(NP INTERNET/NN bytemark/NN makes/VBZ first/JJ acquisition/NN)\n",
      "(NP sold/VBN rotten/RB retirement/JJ)\n",
      "(NP sold/VBN rotten/RB retirement/JJ)\n",
      "(NP deal/NN creates/VBZ largest/JJS travel/NN)\n",
      "(NP\n",
      "  retailer/NN\n",
      "  INTERNET/NN\n",
      "  deal/NN\n",
      "  creates/VBZ\n",
      "  largest/JJS\n",
      "  travel/NN)\n",
      "(NP debenhams/NNS becomes/VBZ latest/JJS casualty/NN)\n",
      "(NP debenhams/NNS becomes/VBZ latest/JJS casualty/NN)\n",
      "(NP Name/NNP Name/NNP sees/VBZ strong/JJ trading/NN)\n",
      "(NP INTERNET/NN Name/NNP Name/NNP sees/VBZ strong/JJ trading/NN)\n",
      "(NP Name/NNP approves/VBZ cross-border/JJ fines/NNS)\n",
      "(NP INTERNET/NNP Name/NNP approves/VBZ cross-border/JJ fines/NNS)\n",
      "(NP football/NN gives/VBZ new/JJ yorkers/NNS)\n",
      "(NP pitch/NN INTERNET/NN football/NN gives/VBZ new/JJ yorkers/NNS)\n",
      "(NP\n",
      "  northern/NN\n",
      "  quarter/NN\n",
      "  design/NN\n",
      "  emporium/NN\n",
      "  Name/NNP\n",
      "  celebrates/VBZ\n",
      "  new/JJ\n",
      "  home/NN)\n",
      "(NP\n",
      "  northern/NN\n",
      "  quarter/NN\n",
      "  design/NN\n",
      "  emporium/NN\n",
      "  Name/NNP\n",
      "  celebrates/VBZ\n",
      "  new/JJ\n",
      "  home/NN)\n",
      "(NP year/NN winner/NN Name/NNP iota/NN launches/VBZ new/JJ retail/NN)\n",
      "(NP year/NN winner/NN Name/NNP iota/NN launches/VBZ new/JJ retail/NN)\n",
      "(NP Name/NNP industry/NN wants/VBZ new/JJ regulator/NN)\n",
      "(NP industry/NN industry/NN wants/VBZ new/JJ regulator/NN)\n",
      "(NP france/NN pm/NN pushes/VBZ key/JJ reforms/NNS)\n",
      "(NP INTERNET/NNP france/NN pm/NN pushes/VBZ key/JJ reforms/NNS)\n",
      "(NP slide/VBP as/RB brent/JJ)\n",
      "(NP slide/VBP as/RB brent/JJ)\n",
      "(NP footsie/NN makes/VBZ early/JJ gains/NNS)\n",
      "(NP footsie/NN makes/VBZ early/JJ gains/NNS)\n",
      "(NP footsie/NN makes/VBZ positive/JJ start/NN)\n",
      "(NP footsie/NN makes/VBZ positive/JJ start/NN)\n",
      "(NP Name/NNP Name/NNP update/NN sparks/VBZ global/JJ market/NN)\n",
      "(NP Name/NNP Name/NNP update/NN sparks/VBZ global/JJ market/NN)\n",
      "(NP abbvie/NN has/VBZ second/JJ thoughts/NNS)\n",
      "(NP abbvie/NN has/VBZ second/JJ thoughts/NNS)\n",
      "(NP warning/VBG further/RB blow/JJ)\n",
      "(NP toll/NN plan/NN gets/VBZ go-ahead/JJ INTERNET/NN)\n",
      "(NP german/NN road/NN toll/NN plan/NN gets/VBZ go-ahead/JJ BankD/NNP)\n",
      "(NP gmca/NN strikes/VBZ innovative/JJ deal/NN)\n",
      "(NP gmca/NN strikes/VBZ innovative/JJ deal/NN)\n",
      "(NP greece/NN makes/VBZ huge/JJ claim/NN)\n",
      "(NP nazi/NN era/NN INTERNET/NN greece/NN makes/VBZ huge/JJ claim/NN)\n",
      "(NP retreat/NN is/VBZ hassle-free/JJ BankD/NNP)\n",
      "(NP retreat/NN is/VBZ hassle-free/JJ BankD/NNP)\n",
      "(NP imagination/NN Name/NNP poaches/VBZ former/JJ Name/NNP)\n",
      "(NP\n",
      "  Name/NNP\n",
      "  boss/NN\n",
      "  INTERNET/NNP\n",
      "  imagination/NN\n",
      "  Name/NNP\n",
      "  poaches/VBZ\n",
      "  former/JJ\n",
      "  Name/NNP)\n",
      "(NP Name/NNP declines/VBZ new/JJ loans/NNS)\n",
      "(NP inflation/NN rate/NN turns/VBZ negative/JJ INTERNET/NN)\n",
      "(NP inflation/NN rate/NN turns/VBZ negative/JJ BankD/NNP)\n",
      "(NP INTERNET/NN is/VBZ fibre/JJ key/NN)\n",
      "(NP Name/NNP launches/VBZ new/JJ channel/NN)\n",
      "(NP jaffa/NN cakes/VBZ british/JJ maker/NN)\n",
      "(NP jaffa/NN cakes/VBZ british/JJ maker/NN)\n",
      "(NP Name/NNP Name/NNP enjoys/VBZ major/JJ growth/NN)\n",
      "(NP INTERNET/NN Name/NNP Name/NNP enjoys/VBZ major/JJ growth/NN)\n",
      "(NP japan/NN train/NN sets/VBZ new/JJ speed/NN)\n",
      "(NP\n",
      "  record/NN\n",
      "  INTERNET/NNP\n",
      "  japan/NN\n",
      "  train/NN\n",
      "  sets/VBZ\n",
      "  new/JJ\n",
      "  speed/NN)\n",
      "(NP\n",
      "  japan/NN\n",
      "  s/NNS\n",
      "  savings/NNS\n",
      "  rate/NN\n",
      "  turns/VBZ\n",
      "  negative/JJ\n",
      "  INTERNET/NN)\n",
      "(NP\n",
      "  japan/NN\n",
      "  s/NNS\n",
      "  savings/NNS\n",
      "  rate/NN\n",
      "  turns/VBZ\n",
      "  negative/JJ\n",
      "  BankD/NNP)\n",
      "(NP\n",
      "  streaming/NN\n",
      "  brand/NN\n",
      "  INTERNET/NN\n",
      "  jay-z/NN\n",
      "  promotes/VBZ\n",
      "  music/JJ\n",
      "  streaming/NN)\n",
      "(NP\n",
      "  motoring/NN\n",
      "  services/NNS\n",
      "  INTERNET/NNP\n",
      "  Name/NNP\n",
      "  Name/NNP\n",
      "  launches/VBZ\n",
      "  new/JJ\n",
      "  motoring/NN)\n",
      "(NP blow/VBP as/RB refinery/JJ)\n",
      "(NP johnnie/NN walker/NN Name/NNP drinks/VBZ giant/JJ Name/NNP)\n",
      "(NP INTERNET/NNP johnnie/NN Name/NNP drinks/VBZ giant/JJ Name/NNP)\n",
      "(NP malaysia/NN airlines/NNS chooses/VBZ new/JJ chief/NN)\n",
      "(NP malaysia/NN airlines/NNS chooses/VBZ new/JJ chief/NN)\n",
      "(NP ordsall/NN chord/NN gets/VBZ go-ahead/JJ BankD/NNP)\n",
      "(NP surprise/VBP stimulus/RB prog/JJ)\n",
      "(NP purBankDs/NNS goes/VBZ wrong/JJ millions/NNS)\n",
      "(NP purBankDs/NNS goes/VBZ wrong/JJ BankD/NNP)\n",
      "(NP morrisons/NNS names/VBZ new/JJ chief/NN)\n",
      "(NP executive/NN INTERNET/NN morrisons/NNS names/VBZ new/JJ chief/NN)\n",
      "(NP vote/NN vote/NN is/VBZ minor/JJ miracle/NN)\n",
      "(NP vote/NN vote/NN is/VBZ minor/JJ miracle/NN)\n",
      "(NP Name/NNP building/NN gets/VBZ green/JJ light/NN)\n",
      "(NP Name/NNP building/NN gets/VBZ green/JJ light/NN)\n",
      "(NP output/NN remains/VBZ flat/JJ BankD/NNP)\n",
      "(NP Name/NNP capital/NN BankB/NNP s/VBZ total/JJ fitness/NN)\n",
      "(NP\n",
      "  INTERNET/NN\n",
      "  Name/NNP\n",
      "  capital/NN\n",
      "  BankB/NNP\n",
      "  s/VBZ\n",
      "  total/JJ\n",
      "  fitness/NN)\n",
      "(NP stop/VB giving/VBG away/RB free/JJ)\n",
      "(NP stop/VB giving/VBG away/RB free/JJ)\n",
      "(NP poster/NN gives/VBZ the/DT wrong/JJ impression/NN)\n",
      "(NP poster/NN gives/VBZ the/DT wrong/JJ impression/NN)\n",
      "(NP eurozone/NN is/VBZ biggest/JJS risk/NN)\n",
      "(NP peninsula/NN takes/VBZ the/DT high/JJ road/NN)\n",
      "(NP peninsula/NN takes/VBZ the/DT high/JJ road/NN)\n",
      "(NP Name/NNP seeks/VBZ fresh/JJ funding/NN)\n",
      "(NP yearâ/NNP Name/NNP seeks/VBZ fresh/JJ funding/NN)\n",
      "(NP friday-/NN does/VBZ this/DT cynical/JJ retailers/NNS)\n",
      "(NP friday-/NN does/VBZ this/DT cynical/JJ retailers/NNS)\n",
      "(NP ploy/VBP even/RB offer/JJR)\n",
      "(NP Name/NNP admits/VBZ mis-selling/JJ business/NN)\n",
      "(NP Name/NNP admits/VBZ mis-selling/JJ business/NN)\n",
      "(NP Name/NNP says/VBZ bad/JJ loan/NN)\n",
      "(NP Name/NNP says/VBZ bad/JJ loan/NN)\n",
      "(NP pay/NN is/VBZ increasingly/RB ham-fisted/JJ BankD/NNP)\n",
      "(NP\n",
      "  success/NN\n",
      "  INTERNET/NNP\n",
      "  ryanair/NN\n",
      "  celebrates/VBZ\n",
      "  30th/JJ\n",
      "  birthday/NN)\n",
      "(NP sabmiller/NN blames/VBZ poor/JJ weather/NN)\n",
      "(NP sharpfutures/NNS takes/VBZ top/JJ place/NN)\n",
      "(NP west/NN sharpfutures/NNS takes/VBZ top/JJ place/NN)\n",
      "(NP Name/NNP is/VBZ great/JJ britain/NN)\n",
      "(NP Name/NNP is/VBZ great/JJ britain/NN)\n",
      "(NP circle/NN Name/NNP ends/VBZ hospital/JJ deal/NN)\n",
      "(NP circle/NN Name/NNP ends/VBZ hospital/JJ deal/NN)\n",
      "(NP company/NN becomes/VBZ latest/JJS fashion/NN)\n",
      "(NP company/NN becomes/VBZ latest/JJS fashion/NN)\n",
      "(NP Name/NNP expects/VBZ bigger/JJR loss/NN)\n",
      "(NP recall/NN INTERNET/NNP Name/NNP expects/VBZ bigger/JJR loss/NN)\n",
      "(NP Name/NNP uses/VBZ behavioural/JJ psychologists/NNS)\n",
      "(NP Name/NNP uses/VBZ behavioural/JJ psychologists/NNS)\n",
      "(NP tesco/NN asks/VBZ fifth/JJ exec/NN)\n",
      "(NP tesco/NN asks/VBZ fifth/JJ exec/NN)\n",
      "(NP be/VB even/RB worse/JJR)\n",
      "(NP be/VB even/RB worse/JJR)\n",
      "(NP uk/NN productivity/NN shows/VBZ small/JJ rise/NN)\n",
      "(NP INTERNET/NNP uk/NN productivity/NN shows/VBZ small/JJ rise/NN)\n",
      "(NP INTERNET/NN Name/NNP makes/VBZ a/DT good/JJ business/NN)\n",
      "(NP workforce/NN diversity/NN is/VBZ a/DT critical/JJ factor/NN)\n",
      "(NP\n",
      "  business/NN\n",
      "  INTERNET/NN\n",
      "  workforce/NN\n",
      "  diversity/NN\n",
      "  diversity/NN\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  critical/JJ\n",
      "  factor/NN)\n",
      "\n",
      "Key Phrases from Twitter\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Facebook Comments that mention customer service: 1045\n",
      "Twitter Comments that mention customer service: 1175\n",
      "\n",
      "Key Phrases from Facebook\n",
      "(NP customer/NN service/NN is/VBZ terrible/JJ Name/NNP)\n",
      "(NP was/VBD completely/RB rude/JJ)\n",
      "(NP met/VB so/RB many/JJ)\n",
      "(NP say/VBP enough/RB good/JJ)\n",
      "(NP wayne/NN road/NN road/NN is/VBZ the/DT slowest/JJS branch/NN)\n",
      "(NP do/VBP not/RB overnight/JJ)\n",
      "(NP was/VBD so/RB rude/JJ)\n",
      "(NP ba/NN is/VBZ horrible/JJ customer/NN)\n",
      "(NP california/NN has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankB/NNP is/VBZ the/DT only/JJ bank/NN)\n",
      "(NP BankB/NNP has/VBZ the/DT poorest/JJS customer/NN)\n",
      "(NP BankB/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankB/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankB/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP dont/VBP even/RB want/JJ)\n",
      "(NP BankB/NNP is/VBZ the/DT worst/JJS bank/NN)\n",
      "(NP BankB/NNP is/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP is/VBZ truly/RB dead/JJ)\n",
      "(NP be/VB so/RB disrespectful/JJ)\n",
      "(NP is/VBZ extremely/RB unacceptable/JJ)\n",
      "(NP BankB/NNP is/VBZ the/DT worst/JJS bank/NN)\n",
      "(NP was/VBD so/RB nice/JJ)\n",
      "(NP halloween/NN vein/NN is/VBZ the/DT only/JJ way/NN)\n",
      "(NP BankD/NNP bank/NN eliminates/VBZ more/JJR jobs/NNS)\n",
      "(NP BankD/NNP has/VBZ the/DT absolute/JJ worst/NN)\n",
      "(NP is/VBZ very/RB true/JJ)\n",
      "(NP Name/NNP Name/NNP bank/NN eliminates/VBZ more/JJR jobs/NNS)\n",
      "(NP BankC/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP is/VBZ very/RB poor/JJ)\n",
      "(NP phone/NN is/VBZ a/DT terrible/JJ experience/NN)\n",
      "(NP web/NN page/NN is/VBZ a/DT poor/JJ substitute/NN)\n",
      "(NP BankB/NNP has/VBZ any/DT general/JJ policies/NNS)\n",
      "(NP werent/VBD even/RB apologetic/JJ)\n",
      "(NP have/VB been/VBN here/RB last/JJ)\n",
      "(NP are/VBP very/RB important/JJ)\n",
      "(NP was/VBD very/RB vocal/JJ)\n",
      "(NP BankD/NNP has/VBZ the/DT best/JJS customer/NN)\n",
      "(NP was/VBD extremely/RB rude/JJ)\n",
      "(NP cant/VBD even/RB enjoy/JJ)\n",
      "(NP was/VBD still/RB active/JJ)\n",
      "(NP had/VBD so/RB many/JJ)\n",
      "(NP are/VBP non/RB existent/JJ)\n",
      "(NP is/VBZ absolutely/RB clueless/JJ)\n",
      "(NP take/VB so/RB long/JJ)\n",
      "(NP are/VBP here/RB people-/JJ)\n",
      "(NP were/VBD so/RB stupid/JJ)\n",
      "(NP is/VBZ always/RB knowledgeable/JJ)\n",
      "(NP name/NN sounds/VBZ shady/JJ )/NN)\n",
      "(NP am/VBP not/RB happy/JJ)\n",
      "(NP am/VBP so/RB glad/JJ)\n",
      "(NP wasnt/VBP being/VBG overly/RB sensitive/JJ)\n",
      "(NP am/VBP so/RB mad/JJ)\n",
      "(NP was/VBD so/RB nice/JJ)\n",
      "(NP BankA/NNP is/VBZ a/DT big/JJ liar/NN)\n",
      "(NP was/VBD far/RB superior/JJ)\n",
      "(NP was/VBD so/RB small/JJ)\n",
      "(NP were/VBD extremely/RB rude/JJ)\n",
      "(NP do/VBP not/RB open/JJ)\n",
      "(NP hawaii/NN is/VBZ still/RB terrible/JJ customer/NN)\n",
      "(NP is/VBZ just/RB ridiculous/JJ)\n",
      "(NP am/VBP just/RB curious/JJ)\n",
      "(NP was/VBD not/RB possible/JJ)\n",
      "(NP am/VBP so/RB thankful/JJ)\n",
      "(NP is/VBZ so/RB bad/JJ)\n",
      "(NP am/VBP not/RB happy/JJ)\n",
      "(NP was/VBD so/RB strange/JJ)\n",
      "(NP BankB/NNP is/VBZ the/DT worst/JJS bank/NN)\n",
      "(NP is/VBZ not/RB possible/JJ)\n",
      "(NP have/VBP called/VBN so/RB many/JJ)\n",
      "(NP have/VBP been/VBN very/RB patient/JJ)\n",
      "(NP have/VBP been/VBN very/RB professional/JJ)\n",
      "(NP is/VBZ always/RB excellent/JJ)\n",
      "(NP were/VBD so/RB helpful/JJ)\n",
      "(NP is/VBZ not/RB fair/JJ)\n",
      "(NP is/VBZ so/RB bad/JJ)\n",
      "(NP am/VBP pretty/RB sure/JJ)\n",
      "(NP is/VBZ very/RB unreliable/JJ)\n",
      "(NP BankB/NNP has/VBZ great/JJ customer/NN)\n",
      "(NP BankA/NNP is/VBZ the/DT absolute/JJ worst/NN)\n",
      "(NP were/VBD very/RB disrespectful/JJ)\n",
      "(NP is/VBZ not/RB delinquent/JJ)\n",
      "(NP is/VBZ still/RB strong/JJ)\n",
      "(NP BankA/NNP has/VBZ horrible/JJ customer/NN)\n",
      "(NP are/VBP always/RB ready/JJ)\n",
      "(NP dont/VBP even/RB matter/JJR)\n",
      "(NP BankC/NNP INTERNET/NNP is/VBZ the/DT global/JJ source/NN)\n",
      "(NP is/VBZ very/RB sad/JJ)\n",
      "(NP was/VBD very/RB nice/JJ)\n",
      "(NP am/VBP not/RB able/JJ)\n",
      "(NP\n",
      "  BankD/NNP\n",
      "  Name/NNP\n",
      "  BankD/NNP\n",
      "  bank/NN\n",
      "  provides/VBZ\n",
      "  the/DT\n",
      "  worst/JJS\n",
      "  customer/NN)\n",
      "(NP Name/NNP Name/NNP Name/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP Name/NNP is/VBZ the/DT best/JJS bank/NN)\n",
      "(NP feel/VBP so/RB good/JJ)\n",
      "(NP be/VB so/RB happy/JJ)\n",
      "(NP be/VB not/RB knowledgeable/JJ)\n",
      "(NP husband/NN has/VBZ the/DT american/JJ furniture/NN)\n",
      "(NP are/VBP too/RB stupid/JJ)\n",
      "(NP BankA/NNP is/VBZ the/DT new/JJ mob/NN)\n",
      "(NP am/VBP not/RB happy/JJ)\n",
      "(NP im/VBP so/RB livid/JJ)\n",
      "(NP BankA/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankA/NNP is/VBZ the/DT biggest/JJS joke/NN)\n",
      "(NP hate/NN is/VBZ a/DT strong/JJ word/NN)\n",
      "(NP\n",
      "  way/NN\n",
      "  pnc/NN\n",
      "  bank/NN\n",
      "  bank/NN\n",
      "  has/VBZ\n",
      "  this/DT\n",
      "  virtual/JJ\n",
      "  wallet/NN)\n",
      "(NP have/VBP too/RB many/JJ)\n",
      "(NP is/VBZ not/RB good/JJ)\n",
      "(NP am/VBP very/RB new/JJ)\n",
      "(NP BankC/NNP provides/VBZ horrible/JJ customer/NN)\n",
      "(NP dont/VBP even/RB care/JJ)\n",
      "(NP say/VB pretty/RB good/JJ)\n",
      "(NP was/VBD not/RB happy/JJ)\n",
      "(NP BankB/NNP has/VBZ a/DT bad/JJ reputation/NN)\n",
      "(NP is/VBZ so/RB important/JJ)\n",
      "(NP BankB/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP have/VBP very/RB big/JJ)\n",
      "(NP is/VBZ even/RB worse/JJR)\n",
      "(NP BankA/NNP has/VBZ better/JJR customer/NN)\n",
      "(NP montrose/NN has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankA/NNP bank/NN is/VBZ horrible/JJ cant/NN)\n",
      "(NP is/VBZ truly/RB unacceptable/JJ)\n",
      "(NP are/VBP ever/RB able/JJ)\n",
      "(NP been/VBN extremely/RB happy/JJ)\n",
      "(NP BankB/NNP has/VBZ the/DT poorest/JJS customer/NN)\n",
      "(NP bank/NN is/VBZ the/DT worst/JJS bank/NN)\n",
      "(NP is/VBZ very/RB poor/JJ)\n",
      "(NP is/VBZ absolutely/RB ridiculous/JJ)\n",
      "(NP guys/VBZ severely/RB filter/JJR)\n",
      "(NP have/VBP very/RB poor/JJ)\n",
      "(NP was/VBD not/RB able/JJ)\n",
      "(NP was/VBD told/VBN there/RB wasnt/JJ)\n",
      "(NP verizon/NN has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankD/NNP is/VBZ the/DT worst/JJS bank/NN)\n",
      "(NP BankA/NNP is/VBZ a/DT despicable/JJ company/NN)\n",
      "(NP was/VBD very/RB rude/JJ)\n",
      "(NP have/VBP had/VBN so/RB many/JJ)\n",
      "(NP am/VBP now/RB gon/JJ)\n",
      "(NP leaving/VBG august/RB 28th/JJ)\n",
      "(NP BankA/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP are/VBP so/RB rude/JJ)\n",
      "(NP\n",
      "  BankA/NNP\n",
      "  customer/NN\n",
      "  service/NN\n",
      "  department/NN\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  complete/JJ\n",
      "  joke/NN)\n",
      "(NP is/VBZ so/RB offensive/JJ)\n",
      "(NP BankA/NNP has/VBZ terrible/JJ customer/NN)\n",
      "(NP BankA/NNP has/VBZ the/DT absolute/JJ worse/NN)\n",
      "(NP BankA/NNP has/VBZ the/DT absolute/JJ worst/NN)\n",
      "(NP BankA/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankA/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankA/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankA/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankA/NNP is/VBZ a/DT big/JJ liar/NN)\n",
      "(NP BankA/NNP is/VBZ a/DT great/JJ Name/NNP)\n",
      "(NP is/VBZ as/RB bad/JJ)\n",
      "(NP is/VBZ only/RB consistent/JJ)\n",
      "(NP BankA/NNP is/VBZ the/DT worst/JJS bank/NN)\n",
      "(NP BankA/NNP is/VBZ the/DT worst/JJS bank/NN)\n",
      "(NP suck/VBP so/RB bad/JJ)\n",
      "(NP are/VBP so/RB blind/JJ)\n",
      "(NP BankA/NNP offers/VBZ terrible/JJ customer/NN)\n",
      "(NP bank/NN has/VBZ new/JJ tellers/NNS)\n",
      "(NP are/VBP very/RB nice/JJ)\n",
      "(NP is/VBZ not/RB practical/JJ)\n",
      "(NP am/VBP now/RB unable/JJ)\n",
      "(NP BankA/NNP usubanke/NN has/VBZ more/JJR customer/NN)\n",
      "(NP are/VBP too/RB big/JJ)\n",
      "(NP was/VBD now/RB negative/JJ)\n",
      "(NP BankD/NNP bank/NN bank/NN has/VBZ horrible/JJ customer/NN)\n",
      "(NP is/VBZ very/RB rude/JJ)\n",
      "(NP is/VBZ extremely/RB slow/JJ)\n",
      "(NP BankC/NNP provides/VBZ daily/JJ robocalls/NNS)\n",
      "(NP are/VBP so/RB rude/JJ)\n",
      "(NP dont/VBP know/RB great/JJ)\n",
      "(NP company/NN is/VBZ ridiculous/JJ i/NN)\n",
      "(NP is/VBZ still/RB unresolved/JJ)\n",
      "(NP is/VBZ completely/RB different/JJ)\n",
      "(NP BankB/NNP has/VBZ bad/JJ customer/NN)\n",
      "\n",
      "Key Phrases from Twitter\n",
      "(NP twit_hndl_BankB/NNP is/VBZ the/DT worst/JJS bank/NN)\n",
      "(NP were/VBD very/RB helpful/JJ)\n",
      "(NP is/VBZ so/RB attentive/JJ)\n",
      "(NP twit_hndl_BankB/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP customer/NN service/NN is/VBZ human.-/JJ twit_hndl/NNP)\n",
      "(NP was/VBD only/RB able/JJ)\n",
      "(NP twit_hndl_BankA/NNP Name/NNP has/VBZ terrible/JJ customer/NN)\n",
      "(NP is/VBZ too/RB high/JJ)\n",
      "(NP twit_hndl_BankA/NNP has/VBZ the/DT best/JJS customer/NN)\n",
      "(NP was/VBD very/RB helpful/JJ)\n",
      "(NP am/VBP very/RB appreciative/JJ)\n",
      "(NP been/VBN very/RB stressful/JJ)\n",
      "(NP are/VBP very/RB direspectful/JJ)\n",
      "(NP are/VBP hiring/VBG very/RB incompetent/JJ)\n",
      "(NP were/VBD very/RB helpful/JJ)\n",
      "(NP issue/NN is/VBZ incorrect/JJ information/NN)\n",
      "(NP is/VBZ simply/RB pathetic/JJ)\n",
      "(NP are/VBP too/RB big/JJ)\n",
      "(NP was/VBD so/RB helpful/JJ)\n",
      "(NP twit_hndl_BankB/NNP has/VBZ horrible/JJ customer/NN)\n",
      "(NP twit_hndl_BankB/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP twit_hndl_BankB/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP customer/NN service/NN is/VBZ always/RB gon/JJ na/NN)\n",
      "(NP twit_hndl_BankB/NNP is/VBZ the/DT creepiest/JJS bank/NN)\n",
      "(NP are/VBP even/RB worse/JJR)\n",
      "(NP assist/NN is/VBZ an/DT epic/JJ fail/NN)\n",
      "(NP is/VBZ not/RB available/JJ)\n",
      "(NP south/NN state/NN is/VBZ a/DT major/JJ inconvenience/NN)\n",
      "(NP is/VBZ so/RB bad/JJ)\n",
      "(NP\n",
      "  twit_hndl_BankB/NNP\n",
      "  Name/NNP\n",
      "  BankB/NNP\n",
      "  has/VBZ\n",
      "  the/DT\n",
      "  worst/JJS\n",
      "  customer/NN)\n",
      "(NP BankB/NNP is/VBZ the/DT worst/JJS bank/NN)\n",
      "(NP were/VBD not/RB willing/JJ)\n",
      "(NP twit_hndl_BankD/NNP has/VBZ great/JJ customer/NN)\n",
      "(NP twit_hndl_BankD/NNP has/VBZ the/DT best/JJS customer/NN)\n",
      "(NP is/VBZ absolutely/RB horrible/JJ)\n",
      "(NP be/VB very/RB accessible/JJ)\n",
      "(NP twit_hndl_BankC/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP are/VBP very/RB disappointing/JJ)\n",
      "(NP is/VBZ very/RB important/JJ)\n",
      "(NP\n",
      "  twit_hndl/NNP\n",
      "  Name/NNP\n",
      "  heard/NN\n",
      "  BankB/NNP\n",
      "  has/VBZ\n",
      "  terrible/JJ\n",
      "  customer/NN)\n",
      "(NP\n",
      "  twit_hndl/NNP\n",
      "  customer/NN\n",
      "  service/NN\n",
      "  service/NN\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  high/JJ\n",
      "  priority/NN)\n",
      "(NP customer/NN service/NN is/VBZ a/DT high/JJ priority/NN)\n",
      "(NP twit_hndl_BankC/NNP is/VBZ the/DT best/JJS customer/NN)\n",
      "(NP peru/NN office/NN office/NN has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP\n",
      "  twit_hndl_BankA/NNP\n",
      "  twit_hndl_BankA/NNP\n",
      "  has/VBZ\n",
      "  the/DT\n",
      "  worst/JJS\n",
      "  customer/NN)\n",
      "(NP twit_hndl_BankA/NNP has/VBZ great/JJ customer/NN)\n",
      "(NP twit_hndl_BankA/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP twit_hndl_BankA/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP twit_hndl_BankA/NNP has/VBZ the/DT worst/JJS phone/NN)\n",
      "(NP twit_hndl_BankA/NNP BankA/NNP is/VBZ good/JJ customer/NN)\n",
      "(NP was/VBD absolutely/RB wrong/JJ)\n",
      "(NP windows/NNS is/VBZ poor/JJ customer/NN)\n",
      "(NP BankC/NNP is/VBZ the/DT absolute/JJ worst/NN)\n",
      "(NP BankCprestige/NNP is/VBZ the/DT worst/JJS credit/NN)\n",
      "(NP be/VB so/RB disagreeable/JJ)\n",
      "(NP BankB/NNP is/VBZ the/DT worst/JJS bank/NN)\n",
      "(NP experienced/VBN still/RB cant/JJ)\n",
      "(NP BankB/NNP is/VBZ the/DT worst/JJS bank/NN)\n",
      "(NP montgomery/NN dr/NN needs/VBZ better/JJR customer/NN)\n",
      "(NP service/NN is/VBZ such/JJ trash/NN)\n",
      "(NP is/VBZ so/RB slow/JJ)\n",
      "(NP BankD/NNP bank/NN bank/NN has/VBZ horrible/JJ customer/NN)\n",
      "(NP larchmont/NN is/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankC/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankC/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP twit_hndl_BankA/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP are/VBP so/RB cheerful/JJ)\n",
      "(NP\n",
      "  Name-/NN\n",
      "  twit_hndl_BankA/NNP\n",
      "  has/VBZ\n",
      "  the/DT\n",
      "  worst/JJS\n",
      "  customer/NN)\n",
      "(NP coming/VBG here/RB poor/JJ)\n",
      "(NP cant/VBP even/RB answer/JJR)\n",
      "(NP tempe/NN has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankA/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP twit_hndl/NNP has/VBZ better/JJR customer/NN)\n",
      "(NP been/VBN so/RB livid/JJ)\n",
      "(NP twit_hndl_BankB/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP\n",
      "  god/NN\n",
      "  twit_hndl_BankB_news/NNP\n",
      "  has/VBZ\n",
      "  the/DT\n",
      "  absolute/JJ\n",
      "  worst/NN)\n",
      "(NP is/VBZ so/RB horrible/JJ)\n",
      "(NP twit_hndl_BankA/NNP has/VBZ the/DT best/JJS customer/NN)\n",
      "(NP inquiry/NN is/VBZ so/RB simple/JJ twit_hndl_BankB/NNP)\n",
      "(NP tempe/NN has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankB/NNP is/VBZ the/DT worst/JJS bank/NN)\n",
      "(NP BankC/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankB/NNP is/VBZ the/DT worst/JJS bank/NN)\n",
      "(NP experienced/VBN still/RB cant/JJ)\n",
      "(NP twit_hndl_BankA/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP twit_hndl_BankB/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP twit_hndl_BankA/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankB/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP twit_hndl_BankB/NNP is/VBZ the/DT worst/JJS bank/NN)\n",
      "(NP BankC/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankA/NNP usubanke/NN has/VBZ great/JJ customer/NN)\n",
      "(NP twit_hndl/NNP has/VBZ better/JJR customer/NN)\n",
      "(NP\n",
      "  Name/NNP\n",
      "  twit_hndl_BankA/NNP\n",
      "  has/VBZ\n",
      "  the/DT\n",
      "  worst/JJS\n",
      "  customer/NN)\n",
      "(NP is/VBZ so/RB bad/JJ)\n",
      "(NP twit_hndl_BankC/NNP is/VBZ the/DT best/JJS customer/NN)\n",
      "(NP twit_hndl_BankB/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP twit_hndl_BankA/NNP is/VBZ the/DT worst/JJS company/NN)\n",
      "(NP twit_hndl_BankB/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP customer/NN service/NN is/VBZ human.-/JJ twit_hndl/NNP)\n",
      "(NP BankCprestige/NNP is/VBZ the/DT worst/JJS credit/NN)\n",
      "(NP BankB/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankA/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP twit_hndl_BankB/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankC/NNP is/VBZ the/DT absolute/JJ worst/NN)\n",
      "(NP twit_hndl_BankA/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP\n",
      "  god/NN\n",
      "  twit_hndl_BankB_news/NNP\n",
      "  has/VBZ\n",
      "  the/DT\n",
      "  absolute/JJ\n",
      "  worst/NN)\n",
      "(NP is/VBZ always/RB good/JJ)\n",
      "(NP twit_hndl_BankA/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP having/VBG surprisingly/RB awesome/JJ)\n",
      "(NP are/VBP always/RB super/JJR)\n",
      "(NP been/VBN so/RB great/JJ)\n",
      "(NP twit_hndl_BankA/NNP has/VBZ great/JJ customer/NN)\n",
      "(NP Name/NNP Name/NNP has/VBZ great/JJ customer/NN)\n",
      "(NP twit_hndl_BankA/NNP is/VBZ the/DT worst/JJS company/NN)\n",
      "(NP hold/VBN again/RB due/JJ)\n",
      "(NP company/NN is/VBZ an/DT american/JJ mult/NN)\n",
      "(NP BankA/NNP has/VBZ a/DT good/JJ customer/NN)\n",
      "(NP BankA/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "(NP BankA/NNP needs/VBZ more/JJR customer/NN)\n",
      "(NP inquiry/NN is/VBZ so/RB simple/JJ twit_hndl_BankB/NNP)\n",
      "(NP wow/NN twit_hndl_BankA/NNP has/VBZ the/DT worst/JJS customer/NN)\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Facebook Comments that mention credit card: 769\n",
      "Twitter Comments that mention credit card: 1733\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-f9b3c405b013>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Twitter Comments that mention %s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtw_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mfb_tagged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpos_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcomment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfb_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FullText\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtw_tagged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpos_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcomment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtw_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FullText\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-f9b3c405b013>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Twitter Comments that mention %s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtw_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mfb_tagged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpos_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcomment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfb_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FullText\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtw_tagged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpos_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcomment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtw_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FullText\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-98f65318684e>\u001b[0m in \u001b[0;36mpos_tagger\u001b[0;34m(train_sents)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpos_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vijayv/anaconda/lib/python3.4/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en-ptb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpos_tag_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vijayv/anaconda/lib/python3.4/site-packages/nltk/tag/sequential.py\u001b[0m in \u001b[0;36mtag\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vijayv/anaconda/lib/python3.4/site-packages/nltk/tag/sequential.py\u001b[0m in \u001b[0;36mtag_one\u001b[0;34m(self, tokens, index, history)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtagger\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_taggers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vijayv/anaconda/lib/python3.4/site-packages/nltk/tag/sequential.py\u001b[0m in \u001b[0;36mchoose_tag\u001b[0;34m(self, tokens, index, history)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;31m# higher than that cutoff first; otherwise, return None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cutoff_prob\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mpdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vijayv/anaconda/lib/python3.4/site-packages/nltk/classify/maxent.py\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(self, featureset)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprob_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vijayv/anaconda/lib/python3.4/site-packages/nltk/classify/maxent.py\u001b[0m in \u001b[0;36mprob_classify\u001b[0;34m(self, featureset)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mprob_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mfeature_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logarithmic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vijayv/anaconda/lib/python3.4/site-packages/nltk/classify/maxent.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, featureset, label)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;31m# Otherwise, we might want to fire an \"unseen-value feature\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unseen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m                 \u001b[0;31m# Have we seen this fname/fval combination with any label?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mlabel2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get key phrases for each topic\n",
    "for topic in topics:\n",
    "    # separate topics visually when printed\n",
    "    print()\n",
    "    print()\n",
    "    print(\"*\" * 100)\n",
    "    \n",
    "    s = re.compile(topic, re.IGNORECASE)\n",
    "    fb_mask = (dataset[\"MediaType\"] == \"facebook\") &\\\n",
    "        (dataset[\"FullText\"].apply(lambda x: 1 if s.search(x) else 0))\n",
    "    #        (dataset[\"FullText\"].apply(lambda x: len(x)) > 1000)\n",
    "    tw_mask = (dataset[\"MediaType\"] == \"twitter\") &\\\n",
    "        (dataset[\"FullText\"].apply(lambda x: 1 if s.search(x) else 0))\n",
    "    \n",
    "    print()\n",
    "    print(\"Facebook Comments that mention %s: %s\" % (topic, len(dataset[fb_mask])))\n",
    "    print(\"Twitter Comments that mention %s: %s\" % (topic, len(dataset[tw_mask])))\n",
    "    \n",
    "    fb_tagged = [pos_tagger(sent) for comment in dataset[fb_mask][\"FullText\"] for sent in get_sents(comment)]\n",
    "    tw_tagged = [pos_tagger(sent) for comment in dataset[tw_mask][\"FullText\"] for sent in get_sents(comment)]\n",
    "\n",
    "    # {<JJ.*>+<NN.*>+}\n",
    "    noun_chunker = nltk.RegexpParser('''\n",
    "    NP: {(<NN.*|N.*>+<VBZ><DT|RB>?<JJ.*><NN.*|N.*>+?)}\n",
    "        {<VB.*>+<RB><JJ.*>}\n",
    "    ''')\n",
    "    \n",
    "    print()\n",
    "    print(\"Key Phrases from Facebook\")\n",
    "    for line in fb_tagged:\n",
    "        traverse(noun_chunker.parse(line))\n",
    "    \n",
    "    print()\n",
    "    print(\"Key Phrases from Twitter\")\n",
    "    for line in tw_tagged:\n",
    "        traverse(noun_chunker.parse(line))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
