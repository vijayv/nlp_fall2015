{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified Lesk Algorithm: WordNet Definitions for Similarity Comparison ##\n",
    "From http://pydoc.net/Python/nltk/3.0.0b2/nltk.wsd/# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Natural Language Toolkit: Word Sense Disambiguation Algorithms\n",
    "#\n",
    "# Author: Liling Tan <alvations@gmail.com>\n",
    "#\n",
    "# Copyright (C) 2001-2014 NLTK Project\n",
    "# URL: <http://nltk.org/>\n",
    "# For license information, see LICENSE.TXT\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_overlaps_greedy(context, synsets_signatures, pos=None):\n",
    "    \"\"\"\n",
    "    Calculate overlaps between the context sentence and the synset_signature\n",
    "    and returns the synset with the highest overlap.\n",
    "    \n",
    "    :param context: ``context_sentence`` The context sentence where the ambiguous word occurs.\n",
    "    :param synsets_signatures: ``dictionary`` A list of words that 'signifies' the ambiguous word.\n",
    "    :param pos: ``pos`` A specified Part-of-Speech (POS).\n",
    "    :return: ``lesk_sense`` The Synset() object with the highest signature overlaps.\n",
    "    \"\"\"\n",
    "    max_overlaps = 0\n",
    "    lesk_sense = None\n",
    "    for ss in synsets_signatures:\n",
    "        if pos and str(ss.pos()) != pos: # Skips different POS.\n",
    "            continue\n",
    "        overlaps = set(synsets_signatures[ss]).intersection(context)\n",
    "        if len(overlaps) > max_overlaps:\n",
    "            lesk_sense = ss\n",
    "            max_overlaps = len(overlaps)  \n",
    "    if lesk_sense:\n",
    "        return (lesk_sense, lesk_sense.definition())\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lesk(context_sentence, ambiguous_word, pos=None, dictionary=None):\n",
    "    \"\"\"\n",
    "    This function is the implementation of the original Lesk algorithm (1986).\n",
    "    It requires a dictionary which contains the definition of the different\n",
    "    sense of each word. See http://goo.gl/8TB15w\n",
    "\n",
    "        >>> from nltk import word_tokenize\n",
    "        >>> sent = word_tokenize(\"I went to the bank to deposit money.\")\n",
    "        >>> word = \"bank\"\n",
    "        >>> pos = \"n\"\n",
    "        >>> lesk(sent, word, pos)\n",
    "        Synset('bank.n.07')\n",
    "    \n",
    "    :param context_sentence: The context sentence where the ambiguous word occurs.\n",
    "    :param ambiguous_word: The ambiguous word that requires WSD.\n",
    "    :param pos: A specified Part-of-Speech (POS).\n",
    "    :param dictionary: A list of words that 'signifies' the ambiguous word.\n",
    "    :return: ``lesk_sense`` The Synset() object with the highest signature overlaps.\n",
    "    \"\"\"\n",
    "    if not dictionary:\n",
    "        dictionary = {}\n",
    "        for ss in wn.synsets(ambiguous_word):\n",
    "            dictionary[ss] = ss.definition().split()\n",
    "    best_sense = compare_overlaps_greedy(context_sentence, dictionary, pos)\n",
    "    return best_sense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out the code on an example: ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Synset('savings_bank.n.02'), 'a container (usually with a slot in the top) for keeping money at home')\n",
      "(Synset('deposit.v.02'), 'put into a bank account')\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sentence = word_tokenize(\"I went to the bank to deposit money.\")\n",
    "print(lesk(sentence, \"bank\", \"n\"))\n",
    "print(lesk(sentence,\"deposit\", \"v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Exercise: modify this code to print out the chosen definition  in addition to the chosen synset to help determine if the correct sense was selected.##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## See code change in function defintion above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Exercise: try out other sentences containing bank to see how well the algorithm works.##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "(Synset('signal.n.01'), 'any nonverbal action or gesture that encodes a message')\n",
      "(Synset('flux_density.n.01'), '(physics) the number of changes in energy flow across a given surface per unit area')\n"
     ]
    }
   ],
   "source": [
    "print(lesk(word_tokenize(\"Andy is on his laptop computer.\"), \"computer\", \"n\"))\n",
    "print(lesk(word_tokenize(\"A roundabout is better than a traffic signal.\"), \"signal\", \"n\"))\n",
    "print(lesk(word_tokenize(\"Something is a amiss in Apple's patents for the flux capicitor.\"), \"flux\", \"n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Exercise: try out other ambiguous words and contextualizing sentences.##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Synset('biography.n.01'), \"an account of the series of events making up a person's life\")\n",
      "(Synset('meaning.n.02'), 'the idea that is intended')\n",
      "None\n",
      "(Synset('earphone.n.01'), 'electro-acoustic transducer for converting electric signals into sounds; it is held over or inserted into the ear')\n",
      "(Synset('call.v.03'), 'get or try to get into communication (with someone) by telephone')\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(lesk(word_tokenize(\"What is the meaning of life?\"), \"life\", \"n\"))\n",
    "print(lesk(word_tokenize(\"What is the meaning of life?\"), \"meaning\", \"n\"))\n",
    "print(lesk(word_tokenize(\"Did you phone him earlier today?\"), \"phone\", \"v\"))\n",
    "print(lesk(word_tokenize(\"Did you get the new phone?\"), \"phone\", \"n\"))\n",
    "print(lesk(word_tokenize(\"Did you phone him on the telephone earlier today?\"), \"phone\", \"v\"))\n",
    "print(lesk(word_tokenize(\"A newspaper reporter will be phoning you later.\"), \"phoning\", \"v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Exercise: (optional, for later) What happens with ties in the number of overlaps? ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tie!  2\n",
      "Synset('meaning.n.01') Synset('meaning.n.02')\n",
      "(Synset('meaning.n.02'), 'the idea that is intended')\n"
     ]
    }
   ],
   "source": [
    "print(lesk(word_tokenize(\"What is the meaning of life?\"), \"meaning\", \"n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
